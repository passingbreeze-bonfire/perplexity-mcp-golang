# Perplexity MCP Server Configuration
# Copy this file to .env and set your actual values

# Required: Your Perplexity API key
# Get one at: https://docs.perplexity.ai/docs/getting-started
PERPLEXITY_API_KEY=your-perplexity-api-key-here

# Optional: Default AI model to use
# Available models: llama-3.1-sonar-small-128k-online, llama-3.1-sonar-large-128k-online, 
# sonar-deep-research, sonar-reasoning, sonar-reasoning-pro
PERPLEXITY_DEFAULT_MODEL=llama-3.1-sonar-small-128k-online

# Optional: Request timeout in seconds (default: 30)
REQUEST_TIMEOUT_SECONDS=30

# Optional: Logging level (default: info)
# Available levels: debug, info, warn, error
LOG_LEVEL=info